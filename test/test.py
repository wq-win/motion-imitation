import os
import pickle
import numpy as np
import torch
import inspect
currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))
parentdir = os.path.dirname(currentdir)
print(parentdir)
os.sys.path.insert(0, parentdir)
from pretrain import pretrain_fc_deep 
# test_model = pretrain_fc_deep.Net(160, 12)
# test_model.load_state_dict(torch.load('pretrain_model/predict_model_06-03_13-21-39.pkl', map_location=torch.device('cpu')))
# # print(test_model)    

with open('dataset/o_a_collect_nums_1000.pkl', 'rb') as f:
            allresult = pickle.load(f)

o = np.array(allresult['o'], dtype=float)
a = np.array(allresult['a'])
for i in range(40):
    print(a[i])
    
"""
[ 0.55175805 -1.4982581  -1.5648396  -0.3415988   0.77253884 -0.40795705
  1.3779224  -1.5740747  -0.6434828  -0.54091144  1.2164903  -0.4559414 ]
[-0.86789745 -0.02603071  1.4893284   0.30601433 -0.2775147   0.16607744
 -1.4735073   1.2536412   0.68118894  0.5998226  -0.7280118   0.7134666 ]
[ 1.0165426   0.00960573 -0.70433235 -0.21312281  0.10781089  0.4055001
  1.9492412  -1.2831348  -0.5980853  -1.3685104   1.0807254  -0.80668795]

[-0.8014405  -0.3091513  -0.33432916 -0.00580424  0.8126774  -0.6104709
 -1.4589231   0.41280714  0.22288823  0.91132426  0.60843706  0.1824459 ]

[ 0.9558486  -0.21873489 -0.11491672 -0.195227   -0.4918669   0.22663862
  1.2725897   0.05435651 -0.40598953 -0.91093284 -0.49783167 -0.8308193 ]

[-0.89245117  0.45665067 -0.11234082  0.0432438   0.86937994 -0.9209958
 -0.13361976 -0.37423718  0.27757773  0.37132666  1.0137906  -0.246702  ]

[ 0.7795977  -0.4429102  -0.72931933 -0.45235762 -0.31201577 -0.64189756
 -0.21718742  0.46818787 -0.61019444 -0.56976575 -0.6510046  -0.6485646 ]

[-0.49878958  0.57915574  0.4869963  -0.14407815 -0.2409573  -0.1885979
  1.0416073  -0.12696682  0.18973985  0.17481486 -0.4981571  -0.01126191]

[ 0.28790596 -0.01775892 -0.666033   -0.43204087 -0.38617432 -0.92404073
 -0.78681195  0.10194121 -0.33338714 -0.3342059  -0.09848362 -0.46751162]

[ 0.19660065  0.05965037  0.01417444 -0.32133105 -0.8434205   0.24490695
  1.2234125   0.46813536  0.06661916 -0.4211705  -0.6975899   0.39123765]
  """
  
"""
  para:0.1, step_ave:66.60396039603961, max:146
para:0.11, step_ave:62.277227722772274, max:192
para:0.12, step_ave:67.0, max:202
para:0.13, step_ave:70.94059405940594, max:186
para:0.14, step_ave:57.73267326732673, max:144
para:0.15, step_ave:65.99009900990099, max:235
para:0.16, step_ave:72.61386138613861, max:292
para:0.17, step_ave:68.4950495049505, max:290
para:0.18, step_ave:72.91089108910892, max:355
para:0.19, step_ave:72.61386138613861, max:278
para:0.2, step_ave:75.91089108910892, max:463
para:0.21, step_ave:60.13861386138614, max:154
para:0.22, step_ave:67.99009900990099, max:188
para:0.23, step_ave:66.44554455445545, max:196
para:0.24, step_ave:59.693069306930695, max:213
para:0.25, step_ave:64.04950495049505, max:189
para:0.26, step_ave:64.02970297029702, max:212
para:0.27, step_ave:70.04950495049505, max:239
para:0.28, step_ave:65.96039603960396, max:273
para:0.29, step_ave:68.60396039603961, max:229
para:0.3, step_ave:58.87128712871287, max:171
para:0.31, step_ave:58.881188118811885, max:209
para:0.32, step_ave:71.42574257425743, max:253
para:0.33, step_ave:70.14851485148515, max:284
para:0.34, step_ave:62.54455445544554, max:224
para:0.35000000000000003, step_ave:81.27722772277228, max:307
para:0.36, step_ave:68.56435643564356, max:251
para:0.37, step_ave:69.86138613861387, max:314
para:0.38, step_ave:76.79207920792079, max:401
para:0.39, step_ave:77.54455445544555, max:392
para:0.4, step_ave:61.98019801980198, max:374
para:0.41000000000000003, step_ave:65.72277227722772, max:286

para:0.2, step_ave:68.74257425742574
para:0.21000000000000002, step_ave:65.07920792079207
para:0.22000000000000003, step_ave:70.51485148514851
para:0.23000000000000004, step_ave:59.772277227722775
para:0.24000000000000005, step_ave:68.84158415841584
para:0.25000000000000006, step_ave:71.04950495049505
para:0.26000000000000006, step_ave:66.23762376237623
para:0.2700000000000001, step_ave:68.74257425742574
para:0.2800000000000001, step_ave:60.039603960396036
para:0.2900000000000001, step_ave:65.70297029702971
para:0.3000000000000001, step_ave:63.73267326732673
para:0.3100000000000001, step_ave:58.62376237623762
para:0.3200000000000001, step_ave:66.38613861386139
para:0.3300000000000001, step_ave:71.31683168316832
para:0.34000000000000014, step_ave:63.71287128712871
para:0.35000000000000014, step_ave:73.7128712871287
para:0.36000000000000015, step_ave:73.4950495049505
para:0.37000000000000016, step_ave:70.58415841584159
para:0.38000000000000017, step_ave:67.13861386138613
para:0.3900000000000002, step_ave:76.64356435643565

para:0.38, step_ave:76.4059405940594
para:0.39, step_ave:67.13861386138613
para:0.4, step_ave:54.05940594059406
para:0.41000000000000003, step_ave:64.87128712871286
para:0.42000000000000004, step_ave:60.415841584158414
para:0.43000000000000005, step_ave:62.31683168316832
para:0.44000000000000006, step_ave:56.78217821782178
para:0.45000000000000007, step_ave:65.67326732673267
para:0.4600000000000001, step_ave:51.89108910891089
para:0.4700000000000001, step_ave:57.05940594059406
para:0.4800000000000001, step_ave:48.84158415841584
para:0.4900000000000001, step_ave:49.62376237623762
para:0.5000000000000001, step_ave:43.257425742574256
para:0.5100000000000001, step_ave:39.75247524752475
para:0.5200000000000001, step_ave:45.95049504950495
para:0.5300000000000001, step_ave:41.15841584158416
para:0.5400000000000001, step_ave:44.40594059405941
para:0.5500000000000002, step_ave:48.00990099009901
para:0.5600000000000002, step_ave:43.16831683168317
para:0.5700000000000002, step_ave:36.97029702970297
para:0.5800000000000002, step_ave:38.584158415841586
para:0.5900000000000002, step_ave:36.366336633663366
para:0.6000000000000002, step_ave:36.23762376237624
para:0.6100000000000002, step_ave:30.633663366336634
para:0.6200000000000002, step_ave:38.28712871287129
para:0.6300000000000002, step_ave:33.603960396039604
para:0.6400000000000002, step_ave:31.178217821782177
para:0.6500000000000002, step_ave:33.64356435643565
para:0.6600000000000003, step_ave:29.81188118811881
para:0.6700000000000003, step_ave:28.465346534653467
para:0.6800000000000003, step_ave:29.85148514851485
para:0.6900000000000003, step_ave:28.514851485148515
para:0.7000000000000003, step_ave:30.712871287128714
para:0.7100000000000003, step_ave:26.485148514851485
para:0.7200000000000003, step_ave:27.425742574257427
para:0.7300000000000003, step_ave:27.405940594059405
para:0.7400000000000003, step_ave:27.366336633663366
para:0.7500000000000003, step_ave:24.742574257425744
para:0.7600000000000003, step_ave:24.524752475247524
para:0.7700000000000004, step_ave:25.514851485148515
para:0.7800000000000004, step_ave:25.336633663366335
para:0.7900000000000004, step_ave:25.247524752475247
para:0.8000000000000004, step_ave:22.504950495049506
para:0.8100000000000004, step_ave:23.752475247524753
para:0.8200000000000004, step_ave:23.346534653465348
para:0.8300000000000004, step_ave:24.15841584158416
para:0.8400000000000004, step_ave:22.93069306930693
para:0.8500000000000004, step_ave:22.623762376237625
para:0.8600000000000004, step_ave:22.861386138613863
para:0.8700000000000004, step_ave:21.84158415841584
para:0.8800000000000004, step_ave:21.04950495049505
para:0.8900000000000005, step_ave:21.623762376237625
para:0.9000000000000005, step_ave:21.475247524752476
para:0.9100000000000005, step_ave:20.07920792079208
para:0.9200000000000005, step_ave:22.277227722772277
para:0.9300000000000005, step_ave:20.287128712871286
para:0.9400000000000005, step_ave:22.10891089108911
para:0.9500000000000005, step_ave:19.722772277227723
para:0.9600000000000005, step_ave:21.26732673267327
para:0.9700000000000005, step_ave:21.752475247524753
para:0.9800000000000005, step_ave:20.247524752475247
para:0.9900000000000005, step_ave:19.85148514851485
para:1.0000000000000004, step_ave:20.594059405940595
para:1.0100000000000007, step_ave:19.91089108910891
para:1.0200000000000005, step_ave:19.554455445544555
para:1.0300000000000007, step_ave:20.04950495049505
para:1.0400000000000005, step_ave:18.316831683168317
para:1.0500000000000007, step_ave:17.405940594059405
para:1.0600000000000005, step_ave:20.247524752475247
para:1.0700000000000007, step_ave:19.14851485148515
para:1.0800000000000005, step_ave:18.564356435643564
para:1.0900000000000007, step_ave:18.663366336633665
para:1.1000000000000005, step_ave:17.712871287128714
para:1.1100000000000008, step_ave:17.96039603960396
para:1.1200000000000006, step_ave:18.326732673267326
para:1.1300000000000008, step_ave:18.257425742574256
para:1.1400000000000006, step_ave:17.613861386138613
para:1.1500000000000008, step_ave:18.445544554455445
para:1.1600000000000006, step_ave:17.97029702970297
para:1.1700000000000008, step_ave:17.376237623762375
para:1.1800000000000006, step_ave:17.940594059405942
para:1.1900000000000008, step_ave:17.15841584158416
para:1.2000000000000006, step_ave:17.742574257425744
para:1.2100000000000009, step_ave:17.11881188118812
para:1.2200000000000006, step_ave:17.554455445544555
para:1.2300000000000009, step_ave:16.871287128712872
para:1.2400000000000007, step_ave:16.405940594059405

0.35000000000000003 81.27722772277228
  """